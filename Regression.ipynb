bozorgpanah-patch-1
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bozorgpanah/WASP-Software-Engineering-Project/blob/bozorgpanah-patch-1/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Lyz7LtEUsQ"
      },
      "source": [
        "#Regression>>>predict the output of a continuous value\n",
        "#Dataset>>>classic Auto MPG \n",
        "!pip install tensorflow --upgrade\n",
        "\n",
        "# Use seaborn for pairplot\n",
        "!pip install seaborn\n",
        "\n",
        "# Use some functions from tensorflow_docs\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "\n",
        "print(tf.__version__)\n",
        "name_db = \"auto-mpg.data\"\n",
        "address_db = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\n",
        "EPOCHS = 1000\n",
        "\n",
        "\n",
        "\n",
        "#--downloading_dataset(name_db, address_db)\n",
        "\n",
        "#Importing the data using Pandas library\n",
        "def preprocessing_dataset(columnNames):\n",
        " raw_dataset = pd.read_csv(dataset_path, names=columnNames, na_values = \"?\", comment='\\t', sep=\" \", skipinitialspace=True)\n",
        " dataset = raw_dataset.copy() \n",
        " dataset.tail()\n",
        " #Cleanin the data\n",
        " dataset.isna().sum()\n",
        " dataset = dataset.dropna()\n",
        " dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
        " dataset = pd.get_dummies(dataset, prefix='', prefix_sep='') \n",
        " return dataset.tail()\n",
        "\n",
        "#Normalizing the data\n",
        "def norm(x): \n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "#Inspecting the model\n",
        "def inspect_model():\n",
        " model = build_model()\n",
        " model.summary()\n",
        " example_batch = normed_train_data[:10]\n",
        " example_result = model.predict(example_batch)\n",
        " return example_result\n",
        "\n",
        "#Making prediction\n",
        "def prediction():\n",
        " test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        " a = plt.axes(aspect='equal')\n",
        " plt.scatter(test_labels, test_predictions)\n",
        " plt.xlabel('True Values [MPG]')\n",
        " plt.ylabel('Predictions [MPG]')\n",
        " lims = [0, 50]\n",
        " plt.xlim(lims)\n",
        " plt.ylim(lims)\n",
        " x_ = plt.plot(lims, lims)\n",
        "\n",
        " error = test_predictions - test_labels\n",
        " plt.hist(error, bins = 25)\n",
        " plt.xlabel(\"Prediction Error [MPG]\")\n",
        " x_ = plt.ylabel(\"Count\")  \n",
        " return plt.show()\n",
        "\n",
        "downloading_dataset(name_db, address_db)\n",
        "preprocessing_dataset(column_names)\n",
        "split_dataset()\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "build_model()\n",
        "inspect_model()\n",
        "train_model(EPOCHS)\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "early_history = model.fit(normed_train_data, train_labels, \n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0, \n",
        "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n",
        "plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')\n",
        "\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "print(\"Testing set Loss: {:5.2f} MPG\".format(loss))\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "print(\"Testing set mse: {:5.2f} MPG\".format(mse))\n",
        "prediction()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}


#Regression>>>predict the output of a continuous value
#Dataset>>>classic Auto MPG 
!pip install tensorflow --upgrade

# Use seaborn for pairplot
!pip install seaborn

# Use some functions from tensorflow_docs
!pip install git+https://github.com/tensorflow/docs

from __future__ import absolute_import, division, print_function, unicode_literals
import pathlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

print(tf.__version__)
name_db = "auto-mpg.data"
address_db = "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']
EPOCHS = 1000

#Downloading the dataset
def downloading_dataset(name,address):
  dataset_path = keras.utils.get_file(name, address)
  return dataset_path

#Spliting the data into train and test
def split_dataset():
 train_dataset = dataset.sample(frac=0.8,random_state=0)
 test_dataset = dataset.drop(train_dataset.index)
 sns.pairplot(train_dataset[["MPG", "Cylinders", "Displacement", "Weight"]], diag_kind="kde") #Graph
 #overall statistics
 train_stats = train_dataset.describe()
 train_stats.pop("MPG")
 train_stats = train_stats.transpose()
 train_stats

 #Splitting features from labels
 train_labels = train_dataset.pop('MPG')
 test_labels = test_dataset.pop('MPG')
 return train_labels, test_labels

#Building the model
def build_model():
  model = keras.Sequential([layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]), layers.Dense(64, activation='relu'), layers.Dense(1)])
  optimizer = tf.keras.optimizers.RMSprop(0.001)
  model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])
  return model

#Training the model
def train_model(EP):
 history = model.fit(normed_train_data, train_labels, epochs=EP, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
 hist = pd.DataFrame(history.history)
 hist['epoch'] = history.epoch
 hist.tail()
 plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)
 plotter.plot({'Basic': history}, metric = "mae")
 plt.ylim([0, 10])
 plt.ylabel('MAE [MPG]')
 plotter.plot({'Basic': history}, metric = "mse")
 plt.ylim([0, 20])
 plt.ylabel('MSE [MPG^2]') 
 return plt.show()

main
