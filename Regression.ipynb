{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bozorgpanah/WASP-Software-Engineering-Project/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYB0w-j_jTf"
      },
      "source": [
        "#Regression>>>predict the output of a continuous value\r\n",
        "#Dataset>>>classic Auto MPG \r\n",
        "!pip install tensorflow --upgrade\r\n",
        "\r\n",
        "# Use seaborn for pairplot\r\n",
        "!pip install seaborn\r\n",
        "\r\n",
        "# Use some functions from tensorflow_docs\r\n",
        "!pip install git+https://github.com/tensorflow/docs\r\n",
        "\r\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "import pathlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "try:\r\n",
        "  # %tensorflow_version only exists in Colab.\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow_docs as tfdocs\r\n",
        "import tensorflow_docs.plots\r\n",
        "import tensorflow_docs.modeling\r\n",
        "\r\n",
        "print(tf.__version__)\r\n",
        "\r\n",
        "#Downloading the dataset\r\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\r\n",
        "dataset_path\r\n",
        "\r\n",
        "#Importing the data using Pandas library\r\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\r\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t', sep=\" \", skipinitialspace=True)\r\n",
        "dataset = raw_dataset.copy()\r\n",
        "dataset.tail()\r\n",
        "\r\n",
        "#Cleanin the data\r\n",
        "dataset.isna().sum()\r\n",
        "dataset = dataset.dropna()\r\n",
        "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\r\n",
        "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\r\n",
        "dataset.tail()\r\n",
        "\r\n",
        "#Spliting the data into train and test\r\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\r\n",
        "test_dataset = dataset.drop(train_dataset.index)\r\n",
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\") #Graph\r\n",
        "#overall statistics\r\n",
        "train_stats = train_dataset.describe()\r\n",
        "train_stats.pop(\"MPG\")\r\n",
        "train_stats = train_stats.transpose()\r\n",
        "train_stats\r\n",
        "\r\n",
        "#Splitting features from labels\r\n",
        "train_labels = train_dataset.pop('MPG')\r\n",
        "test_labels = test_dataset.pop('MPG')\r\n",
        "#Normalizing the data\r\n",
        "def norm(x):\r\n",
        "  return (x - train_stats['mean']) / train_stats['std']\r\n",
        "normed_train_data = norm(train_dataset)\r\n",
        "normed_test_data = norm(test_dataset)\r\n",
        "\r\n",
        "#Building the model\r\n",
        "def build_model():\r\n",
        "  model = keras.Sequential([layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]), layers.Dense(64, activation='relu'), layers.Dense(1)])\r\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\r\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\r\n",
        "  return model\r\n",
        "\r\n",
        "model = build_model()\r\n",
        "\r\n",
        "#Inspecting the model\r\n",
        "model.summary()\r\n",
        "example_batch = normed_train_data[:10]\r\n",
        "example_result = model.predict(example_batch)\r\n",
        "example_result\r\n",
        "\r\n",
        "#Training the model\r\n",
        "EPOCHS = 1000\r\n",
        "\r\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS, validation_split = 0.2, \r\n",
        "                    verbose=0, callbacks=[tfdocs.modeling.EpochDots()])\r\n",
        "hist = pd.DataFrame(history.history)\r\n",
        "print(hist, end='\\n')\r\n",
        "hist['epoch'] = history.epoch\r\n",
        "hist.tail()\r\n",
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\r\n",
        "plotter.plot({'Basic': history}, metric = \"mae\")\r\n",
        "plt.ylim([0, 10])\r\n",
        "plt.ylabel('MAE [MPG]')\r\n",
        "plotter.plot({'Basic': history}, metric = \"mse\")\r\n",
        "plt.ylim([0, 20])\r\n",
        "plt.ylabel('MSE [MPG^2]')\r\n",
        "\r\n",
        "model = build_model()\r\n",
        "\r\n",
        "# The patience parameter is the amount of epochs to check for improvement\r\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\r\n",
        "\r\n",
        "early_history = model.fit(normed_train_data, train_labels, \r\n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0, \r\n",
        "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\r\n",
        "plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\r\n",
        "plt.ylim([0, 10])\r\n",
        "plt.ylabel('MAE [MPG]')\r\n",
        "\r\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\r\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\r\n",
        "print(\"Testing set MSE: {:5.2f} MPG\".format(mse))\r\n",
        "print(\"Testing set Loss: {:5.2f} MPG\".format(loss))\r\n",
        "\r\n",
        "#Making prediction\r\n",
        "test_predictions = model.predict(normed_test_data).flatten()\r\n",
        "\r\n",
        "a = plt.axes(aspect='equal')\r\n",
        "plt.scatter(test_labels, test_predictions)\r\n",
        "plt.xlabel('True Values [MPG]')\r\n",
        "plt.ylabel('Predictions [MPG]')\r\n",
        "lims = [0, 50]\r\n",
        "plt.xlim(lims)\r\n",
        "plt.ylim(lims)\r\n",
        "_ = plt.plot(lims, lims)\r\n",
        "\r\n",
        "error = test_predictions - test_labels\r\n",
        "plt.hist(error, bins = 25)\r\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\r\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEfwvFk5B-na"
      },
      "source": [
        "def test_fit():\r\n",
        "  assert model.fit(564.070984, 22.437719, 564.070984, 559.131714, 22.302734, 559.131714) == 0\r\n",
        "  assert model.fit(513.879761, 21.357210, 513.879761, 507.980621, 21.178234, 507.980621) == 1\r\n",
        "  assert model.fit(463.255859, 20.189146, 463.255859, 450.778381, 19.837639, 450.778381) == 2\r\n",
        "  assert model.fit(406.922943, 18.822338, 406.922943, 387.425171, 18.249229, 387.425171) == 3\r\n",
        "  assert model.fit(5.9705, 1.7080, 5.9705, 7.8259, 2.1053, 7.8259,) == 100\r\n",
        "  assert model.fit(5.3365, 1.5836, 5.3365, 7.7012, 2.0999, 7.7012,) == 200\r\n",
        "  assert model.fit(4.7098, 1.4529, 4.7098, 7.9523, 2.1381, 7.9523,) == 300\r\n",
        "  assert model.fit(4.4066, 1.4014, 4.4066, 8.0648, 2.1912, 8.0648,) == 400\r\n",
        "  assert model.fit(3.8809, 1.3007, 3.8809, 8.2515, 2.2030, 8.2515, ) == 500\r\n",
        "  assert model.fit(3.0778, 1.1236, 3.0778, 7.9727, 2.1150, 7.9727,) == 700\r\n",
        "  assert model.fit(2.8492, 1.0555, 2.8492, 7.8695, 2.0979, 7.8695) == 800\r\n",
        "  assert model.fit(2.5882, 1.0104, 2.5882, 8.0267, 2.1229, 8.0267,) == 900\r\n",
        "  assert model.fit(2.421557, 1.021443, 2.421557, 7.761631, 2.131796, 7.761631) == 995\r\n",
        "  assert model.fit(2.417806, 0.946623, 2.417806, 7.872272, 2.109151, 7.872272) == 996\r\n",
        "  assert model.fit(2.397120, 0.978255, 2.397120, 8.160164, 2.095555, 8.160164) == 997\r\n",
        "  assert model.fit(2.497679, 1.040963, 2.497679, 7.729835, 2.142477, 7.729835) == 999\r\n"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}