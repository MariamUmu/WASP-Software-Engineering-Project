{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression&.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bozorgpanah/WASP-Software-Engineering-Project/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKWt7vOoqCEc"
      },
      "source": [
        "!pip install tensorflow --upgrade\r\n",
        "\r\n",
        "# Use seaborn for pairplot\r\n",
        "!pip install seaborn\r\n",
        "\r\n",
        "# Use some functions from tensorflow_docs\r\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYB0w-j_jTf"
      },
      "source": [
        "#Regression>>>predict the output of a continuous value\r\n",
        "#Dataset>>>classic Auto MPG \r\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "import pathlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "try:\r\n",
        "  # %tensorflow_version only exists in Colab.\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "import tensorflow_docs as tfdocs\r\n",
        "import tensorflow_docs.plots\r\n",
        "import tensorflow_docs.modeling\r\n",
        "\r\n",
        "print(tf.__version__)\r\n",
        "name_db = \"auto-mpg.data\"\r\n",
        "address_db = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\r\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\r\n",
        "EPOCHS = 1000\r\n",
        "\r\n",
        "#M\r\n",
        "#Downloading the dataset\r\n",
        "def downloading_dataset(name,address):\r\n",
        "  dataset_path = keras.utils.get_file(name, address)\r\n",
        "  return dataset_path\r\n",
        "\r\n",
        "#A\r\n",
        "#Importing the data using Pandas library\r\n",
        "def preprocessing_dataset(dataset_path, columnNames):\r\n",
        " raw_dataset = pd.read_csv(dataset_path, names=columnNames, na_values = \"?\", comment='\\t', sep=\" \", skipinitialspace=True)\r\n",
        " dataset = raw_dataset.copy() \r\n",
        " dataset.tail()\r\n",
        " #Cleanin the data\r\n",
        " dataset.isna().sum()\r\n",
        " dataset = dataset.dropna()\r\n",
        " dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\r\n",
        " dataset = pd.get_dummies(dataset, prefix='', prefix_sep='') \r\n",
        " dataset.tail()\r\n",
        " #Spliting the data into train and test\r\n",
        " #def split_dataset():\r\n",
        " train_dataset = dataset.sample(frac=0.8,random_state=0)\r\n",
        " test_dataset = dataset.drop(train_dataset.index)\r\n",
        " sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\") #Graph\r\n",
        " #overall statistics\r\n",
        " train_stats = train_dataset.describe()\r\n",
        " train_stats.pop(\"MPG\")\r\n",
        " train_stats = train_stats.transpose()\r\n",
        " train_stats\r\n",
        " #Splitting features from labels\r\n",
        " train_labels = train_dataset.pop('MPG')\r\n",
        " test_labels = test_dataset.pop('MPG')\r\n",
        " return train_stats, train_labels, test_labels\r\n",
        "\r\n",
        "#A\r\n",
        "#Normalizing the data\r\n",
        "def norm(x, train_stats): \r\n",
        "  return (x - train_stats['mean']) / train_stats['std']\r\n",
        "\r\n",
        "#M\r\n",
        "#Building the model\r\n",
        "def build_model():\r\n",
        "  model = keras.Sequential([layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]), layers.Dense(64, activation='relu'), layers.Dense(1)])\r\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\r\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\r\n",
        "  return model\r\n",
        "\r\n",
        "#A\r\n",
        "#Inspecting the model\r\n",
        "def inspect_model(model):\r\n",
        " model = build_model()\r\n",
        " model.summary()\r\n",
        " example_batch = normed_train_data[:10]\r\n",
        " example_result = model.predict(example_batch)\r\n",
        " return example_result\r\n",
        "\r\n",
        "#M\r\n",
        "#Training the model\r\n",
        "def train_model(EP):\r\n",
        " history = model.fit(normed_train_data, train_labels, epochs=EP, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])\r\n",
        " hist = pd.DataFrame(history.history)\r\n",
        " hist['epoch'] = history.epoch\r\n",
        " hist.tail()\r\n",
        " plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\r\n",
        " plotter.plot({'Basic': history}, metric = \"mae\")\r\n",
        " plt.ylim([0, 10])\r\n",
        " plt.ylabel('MAE [MPG]')\r\n",
        " plotter.plot({'Basic': history}, metric = \"mse\")\r\n",
        " plt.ylim([0, 20])\r\n",
        " plt.ylabel('MSE [MPG^2]') \r\n",
        " return plt.show()\r\n",
        "\r\n",
        "#A\r\n",
        "#Making prediction\r\n",
        "def prediction():\r\n",
        " test_predictions = model.predict(normed_test_data).flatten()\r\n",
        "\r\n",
        " a = plt.axes(aspect='equal')\r\n",
        " plt.scatter(test_labels, test_predictions)\r\n",
        " plt.xlabel('True Values [MPG]')\r\n",
        " plt.ylabel('Predictions [MPG]')\r\n",
        " lims = [0, 50]\r\n",
        " plt.xlim(lims)\r\n",
        " plt.ylim(lims)\r\n",
        " _ = plt.plot(lims, lims)\r\n",
        "\r\n",
        " error = test_predictions - test_labels\r\n",
        " plt.hist(error, bins = 25)\r\n",
        " plt.xlabel(\"Prediction Error [MPG]\")\r\n",
        " _ = plt.ylabel(\"Count\")  \r\n",
        " return plt.show()\r\n",
        "##-------------------------------------------------------------------\r\n",
        "dataset_path = downloading_dataset(name_db, address_db)\r\n",
        "train_stats1, train_dataset, test_dataset = preprocessing_dataset(dataset_path, column_names)\r\n",
        "normed_train_data = norm(train_dataset, train_stats1) \r\n",
        "normed_test_data = norm(test_dataset, train_stats1)\r\n",
        "#inspect_model(model_1)#---\r\n",
        "model = build_model()\r\n",
        "model.summary()\r\n",
        "example_batch = normed_train_data[:10]\r\n",
        "example_result = model.predict(example_batch)\r\n",
        "example_result\r\n",
        "\r\n",
        "train_model(EPOCHS)#---\r\n",
        "\r\n",
        "model = build_model()\r\n",
        "\r\n",
        "# The patience parameter is the amount of epochs to check for improvement\r\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\r\n",
        "\r\n",
        "early_history = model.fit(normed_train_data, train_labels, \r\n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0, \r\n",
        "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\r\n",
        "plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\r\n",
        "plt.ylim([0, 10])\r\n",
        "plt.ylabel('MAE [MPG]')\r\n",
        "\r\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\r\n",
        "print(\"Testing set Loss: {:5.2f} MPG\".format(loss))\r\n",
        "#print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\r\n",
        "#print(\"Testing set mse: {:5.2f} MPG\".format(mse))\r\n",
        "prediction()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}